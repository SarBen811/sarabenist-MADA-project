---
title: "Statistical Analysis"
author: "Sara Benist"
date: "2023-04-06"
output: html_document
---

# Processing script with R script code

This Quarto file runs the statistical analysis code from the `statistical_analysis.r` script. The best way to view the output of the script is to render the qmd and view the html document. The processed data is used for model fitting. 

To start, the needed packages are loaded, and the `processeddata.rda` is loaded from the `processed_data` folder. 

# Setup
The `statistical_analysis.r` script needs to be indicated as the file from which to pull code chunks from. 
```{r, cache=FALSE}
knitr::read_chunk('statistical_analysis.R')
```

# Load packages and data
The packages and data are loaded.
```{r, packages, message = FALSE, warning = FALSE}
```

```{r, loaddata}
```

# Basic modelling
For some basic modeling, I will be fitting linear models to the TB outcomes with the subgroups as predictors. This will offer another view of the data. The prediction model also offers a way to explore the data by submitting a sample prediction of TB incidence for females and males in India.
```{r, basicmodels}
```
The biggest issue with the linear modeling is the assumption that the relationship between predictors and outcomes is linear, and the model cannot be tuned and replicated.

# Model fitting
Now that the data has been explored, I would like to start looking at models for the main outcomes and predictors of the data set. First, we will focus split the data into testing and training sets and set up the cross-validation folds. The training set will be used to tune the model parameters and the testing set will be used to test model performance on new data.

```{r, splitdata}

```

I will be tuning decision tree models for the main outcomes of TB incidence, TB mortality, and TB prevalence for both high burden countries and the full data set. 

## Decision tree model for TB Incidence

```{r, wdincidencemodel}
```
The best tree model for TB incidence using the full data has a depth of 4 with an RMSE of 128. This is a very low level of performance in predicting TB incidence. The fitted model to the training data has a RMSE of 62.8, but using the testing data, the model had a performance of RMSE = 110. The most important predictor was country.

```{r, hbincidencemodel}

```
The best tree model for TB incidence using the high burden countries has a depth of 4 with an RMSE of 162. This is also a low level of performance in predicting TB incidence. The fitted model to the training data has a RMSE of 126 which was much higher compared to the full dataset. Using the testing data, the model had a performance of RMSE = 134. The most important predictor was also country.
## Decision tree model for TB Mortality

```{r}
#recipe predicting TB mortality
mortrecipe <- recipe(`TB mortality (deaths per 100 000 population)` ~.,
                 data = wdtrain_data)
#create tree model
treemodel <- decision_tree(
  cost_complexity = tune(),
  tree_depth = tune(),
) %>% 
  set_engine("rpart") %>% 
  set_mode("regression")

#create workflow
mortwflow <- workflow() %>% 
  add_model(treemodel) %>% 
  add_recipe(mortrecipe)

#set seed for reproducibility
set.seed(626)
#resample using cross-validation folds to tune parameters
morttree_resamp <- mortwflow %>% 
  tune_grid(
    resamples = wdfolds,
    grid = tree_grid,
    control = control_grid(save_pred = TRUE)
  )

#plot resampling by parameters
morttreeplot <- morttree_resamp %>% autoplot()
morttreeplot

#show the best model
morttree_resamp %>% 
  show_best()

#select best model
wdmortbest_tree <- morttree_resamp %>% select_best("rmse")

#create final workflow
wdmortfinal_wf <- mortwflow %>% finalize_workflow(wdmortbest_tree)

#fit the final workflow to the training data
wdmortfinal_fit <- wdmortfinal_wf %>% fit(wdtrain_data)

#find RMSE for model with training data
wdmortfitted <- augment(wdmortfinal_fit, wdtrain_data) %>% 
  select(`TB mortality (deaths per 100 000 population)`, .pred) %>% 
  rmse(truth = `TB mortality (deaths per 100 000 population)`, .pred)
wdmortfitted
#fit final workflow to test data
wdmortfittest <- wdmortfinal_fit %>% last_fit(wddatasplit)

#find RMSE for model with test data
wdmortfittest %>% collect_metrics()

#check important variables of model
wdmortfittest %>% extract_fit_parsnip() %>% vip()

```
The best tree model for TB mortality using the full data has a depth of 1 with an RMSE of 16.9. The fitted model to the training data has a RMSE of 11.3, but using the testing data, the model had a performance of RMSE = 17.4. The most important predictor was country.

```{r, hbmortalitymodel}
```
The best tree model for TB mortality using the high burden countries has a depth of 1 with an RMSE of 20.8. The fitted model to the training data has a RMSE of 16.0. Using the testing data, the model had a performance of RMSE = 21.0. The most important predictor was country.

## Decision tree model for TB Prevalence

```{r, wdprevalencemodel}
```
The best tree model for TB prevalence using the full data has a depth of 1 with an RMSE of 208. This is a very low level of performance in predicting TB prevalence. The fitted model to the training data has a RMSE of 135, and using the testing data, the model had a performance of RMSE = 287. The most important predictor was country.

```{r, hbprevalencemodel}
```
The best tree model for TB prevalence using the high burden countries has a depth of 1 with an RMSE of 172. This is a very low level of performance in predicting TB incidence. The fitted model to the training data has a RMSE of 138, but using the testing data, the model had a performance of RMSE = 237. The most important predictor was country.

The models were overall not a good predictor of TB outcomes. This is possibly due to the large variance in the outcomes as well as the low number of predictors available. Since country is consistently the most important predictor, we can look at some of the health indicators to see some of the underlying trends that can occur within a country.

## Decision tree model for BCG coverage

```{r, wdbcgmodel}
```
The best tree model for BCG coverage using the full data has a depth of 15 with an RMSE of 5.86. This would appear to be a better prediction than the previous ones. The fitted model to the training data has a RMSE of 4.29, and using the testing data, the model had a performance of RMSE = 5.30. The most important predictor was country followed by subgroup.

```{r, hbbcgmodel}
```
The best tree model for BCG coverage using high burden countries has a depth of 11 with an RMSE of 5.79. The fitted model to the training data has a RMSE of 4.00, but using the testing data, the model had a performance of RMSE = 5.56. These are approximately similar to the full data set. The most important predictor was country.

## Decision tree model for Catastrophic Cost
```{r, wdcatacostmodel}
```
The best tree model for catastrophic costs using the full data has a depth of 4 with an RMSE of 17.2. The fitted model to the training data has a RMSE of 10.2, but using the testing data, the model had a performance of RMSE = 18.1. The most important predictor was subgroup.

```{r, hbcatacostmodel}
```
The best tree model for catastrophic costs using the high burden countries has a depth of 4 with an RMSE of 16.3. The fitted model to the training data has a RMSE of 10.7, but using the testing data, the model had a performance of RMSE = 15.2. The most important predictor was subgroup.

## Decision tree model for Case Detection Rate

```{r, wdcasedetectmodel}
```
The best tree model for case detection rate using the full data has a depth of 8 with an RMSE of 13.6. The fitted model to the training data has a RMSE of ###, but using the testing data, the model had a performance of RMSE = 12.2. The most important predictor was country.

```{r, hbcasedetectmodel}
```
The best tree model for case detection rate using high burden countries has a depth of 8 with an RMSE of 16.1. This is a very low level of performance in predicting TB incidence. The fitted model to the training data has a RMSE of 7.93, but using the testing data, the model had a performance of RMSE = 11.8. The most important predictor was country.

## Decision tree model for Prevalence to Notification ratio

```{r, wdptnmodel}
```
The best tree model for prevalence to notification ratio using the full data has a depth of 4 with an RMSE of 1.06. This model has the highest performance so far. The fitted model to the training data has a RMSE of 0.546, and using the testing data, the model had a performance of RMSE = 0.656. The most important predictor was country.

```{r, hbptnmodel}
```
The best tree model for prevalence to notification ratio using high burden countries has a depth of 1 with an RMSE of 0.984. This model also has high performance and has a different tree depth than the full data set. The fitted model to the training data has a RMSE of 0.650, but using the testing data, the model had a performance of RMSE = 0.773. The most important and only predictor was country.

## Decision tree model for Male Attitudes

```{r, wdmaleattitudemodel}
```
The best tree model for male attitudes using the full data has a depth of 4 with an RMSE of 5.39. The fitted model to the training data has a RMSE of 3.87, and using the testing data, the model had a performance of RMSE = 4.62. The most important predictor was country.

```{r, hbmaleattitubemodel}
```
The best tree model for male attitude using high burden countries has a depth of 8 with an RMSE of 5.70. The fitted model to the training data has a RMSE of 3.71, but using the testing data, the model had a performance of RMSE = 4.46. The most important predictor was country.

## Decision tree model for Male Knowledge
```{r, wdmaleknowledgemodel}
```
The best tree model for male knowledge using the full data has a depth of 8 with an RMSE of 8.52. The fitted model to the training data has a RMSE of 5.69, but using the testing data, the model had a performance of RMSE = 6.49. The most important predictor was country.

```{r, hbmaleknowledgemodel}
```
The best tree model for male knowledge using the high burden countries has a depth of 4 with an RMSE of 10.8. The fitted model to the training data has a RMSE of 6.23, but using the testing data, the model had a performance of RMSE = 8.99. The most important predictor was year which was different from the full data set.
